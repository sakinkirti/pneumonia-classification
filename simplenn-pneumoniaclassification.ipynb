{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NN to classify chest x-rays as having pnuemonia or normal\nUses dataset from 2018 published in cell: https://data.mendeley.com/datasets/rscbjbr9sj/2 <br>\nTotal training dataset size: 2698 of prebalanced samples (1349 normal/1349 pneumonia) <br>\nTotal testing dataset size: 468 of prebalanced samples (234 normal/234 pneumonia) <br>\nThis equates to a 17/83 train/test split which is a fairly good split to understand the accuracy of the model","metadata":{}},{"cell_type":"markdown","source":"## Table of Contents\n- [1 - Import the packages](#1)\n- [2 - Load the images](#2)\n    - [2.1 - Create the function](#2-1)\n    - [2.2 - Call the function](#2-2)\n    - [2.3 - Test the function](#2-3)\n- [3 - Creating the helper functions](#3)\n    - [3.1 - initializeParameters](#3-1)\n    - [3.2 - modelForward](#3-2)\n        - [3.2.1 - sigmoidActivation](#3-2-1)\n        - [3.2.2 - reluActivation](#3-2-2)\n    - [3.3 - computeCost](#3-3)\n    - [3.4 - modelBackward](#3-4)\n    - [3.5 - updateParameters](#3-5)","metadata":{}},{"cell_type":"markdown","source":"<a name='1'></a>\n## Section 1 - Import necessary packages","metadata":{}},{"cell_type":"code","source":"# for data manipulation\nimport numpy as np\nimport pandas as pd\n\n# for image loading\nfrom PIL import Image, ImageOps\nimport glob\nimport random\n\n# for creating visualizations\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-12-28T06:48:21.711270Z","iopub.execute_input":"2021-12-28T06:48:21.712286Z","iopub.status.idle":"2021-12-28T06:48:21.752211Z","shell.execute_reply.started":"2021-12-28T06:48:21.711963Z","shell.execute_reply":"2021-12-28T06:48:21.751024Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"<a name='2'></a>\n## Section 2 - Load the images\n1. create function to load the images from the folders\n2. call the function to load the data\n3. test by opening some images in each of the datasets","metadata":{}},{"cell_type":"markdown","source":"<a name='2-1'></a>\n### Create the function to load the images from each folder\n- images are stored in different folders\n- iterate through each folder\n- place each image in the right list\n- place its corresponding class in the output list\n- randomize the orders of the testing and training sets","metadata":{}},{"cell_type":"code","source":"# function to load the data sets\ndef loadData(normalTrain, pnuemoTrain, normalTest, pneumoTest):\n    \n    # load the training data details\n    trainXImg = []\n    trainY = []\n    for file in glob.glob(normalTrain):\n        img = Image.open(file)\n        img = ImageOps.grayscale(img)\n        img.thumbnail((720, 720))\n        # crop to the center of the image\n        width, height = img.size\n        left = (width - 720)/2\n        top = (height - 720)/2\n        right = (width + 720)/2\n        bottom = (height + 720)/2\n        img = img.crop((left, top, right, bottom))\n        # save the image to the array\n        trainXImg.append(np.asarray(img))\n        img.close()\n        trainY.append(0)\n    print(\"finished loading normal training images\")\n    for file in glob.glob(pneumoTrain):\n        img = Image.open(file)\n        img = ImageOps.grayscale(img)\n        img.thumbnail((720, 720))\n        # crop to the center of the image\n        width, height = img.size\n        left = (width - 720)/2\n        top = (height - 720)/2\n        right = (width + 720)/2\n        bottom = (height + 720)/2\n        img = img.crop((left, top, right, bottom))\n        # save the image to the array\n        trainXImg.append(np.asarray(img))\n        img.close()\n        trainY.append(1)\n    print(\"finished loading pneumonia training images\")\n\n    # load the testing data details\n    testXImg = []\n    testY = []\n    for file in glob.glob(normalTest):\n        img = Image.open(file)\n        img = ImageOps.grayscale(img)\n        img.thumbnail((720, 720))\n        # crop to the center of the image\n        width, height = img.size\n        left = (width - 720)/2\n        top = (height - 720)/2\n        right = (width + 720)/2\n        bottom = (height + 720)/2\n        img = img.crop((left, top, right, bottom))\n        # save the image to the array\n        testXImg.append(np.asarray(img))\n        img.close()\n        testY.append(0)\n    print(\"finished loading normal testing images\")\n    for file in glob.glob(pneumoTest):\n        img = Image.open(file)\n        img = ImageOps.grayscale(img)\n        img.thumbnail((720, 720))\n        # crop to the center of the image\n        width, height = img.size\n        left = (width - 720)/2\n        top = (height - 720)/2\n        right = (width + 720)/2\n        bottom = (height + 720)/2\n        img = img.crop((left, top, right, bottom))\n        # save the image to the array\n        testXImg.append(np.asarray(img))\n        img.close()\n        testY.append(1)\n    print(\"finished loading pneumonia testing images\")\n    \n    return np.asarray(trainXImg), np.asarray(trainY), np.asarray(testXImg), np.asarray(testY)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T06:48:21.756034Z","iopub.execute_input":"2021-12-28T06:48:21.756855Z","iopub.status.idle":"2021-12-28T06:48:21.779121Z","shell.execute_reply.started":"2021-12-28T06:48:21.756785Z","shell.execute_reply":"2021-12-28T06:48:21.777654Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"<a name='2-2'></a>\n### Call the function to load the images and data\n- store the filepaths\n- call the function and save the outputs","metadata":{}},{"cell_type":"code","source":"# get the folders of the images for training and testing sets\nnormalTrain = \"../input/chest-xray-pneumonia/chest_xray/train/NORMAL/*.jpeg\"\npneumoTrain = \"../input/chest-xray-pneumonia/chest_xray/train/PNEUMONIA*.jpeg\"\nnormalTest = \"../input/chest-xray-pneumonia/chest_xray/test/NORMAL/*.jpeg\"\npneumoTest = \"../input/chest-xray-pneumonia/chest_xray/test/PNEUMONIA*.jpeg\"\n\n# call the function\ntrainXImg, trainY, testXImg, testY = loadData(normalTrain, pneumoTrain, normalTest, pneumoTest)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T06:48:21.781405Z","iopub.execute_input":"2021-12-28T06:48:21.783185Z","iopub.status.idle":"2021-12-28T06:49:47.488609Z","shell.execute_reply.started":"2021-12-28T06:48:21.783105Z","shell.execute_reply":"2021-12-28T06:49:47.487567Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# flatten the images so they are single dimensional arrays\ntrainXFlat = trainXImg.flatten().reshape(518400, -1)\ntestXFlat = testXImg.flatten().reshape(518400, -1)\ntrainY = trainY.reshape(1, trainY.shape[0])\ntestY = testY.reshape(1, testY.shape[0])\n\n# store the row dims of Xtrain and Xtest for training and testing dataset\ntrainXVec = trainXFlat.shape[0]\ntestXVec = testXFlat.shape[0]\n\n# reassign to better named vars\ntrainX = trainXFlat\ntestX = testXFlat","metadata":{"execution":{"iopub.status.busy":"2021-12-28T06:49:47.490331Z","iopub.execute_input":"2021-12-28T06:49:47.490634Z","iopub.status.idle":"2021-12-28T06:49:47.789947Z","shell.execute_reply.started":"2021-12-28T06:49:47.490597Z","shell.execute_reply":"2021-12-28T06:49:47.788990Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"m_train = trainXImg.shape[0]\nm_test = testXImg.shape[0]\nnum_px = trainXImg[1].shape[0]\n\n# YOUR CODE ENDS HERE\n\nprint (\"Number of training examples: m_train = \" + str(m_train))\nprint (\"Number of testing examples: m_test = \" + str(m_test))\nprint (\"Height/Width of each image: num_px = \" + str(num_px))\nprint (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\nprint (\"train_set_x shape: \" + str(trainXImg.shape))\nprint (\"train_set_y shape: \" + str(trainY.shape))\nprint (\"test_set_x shape: \" + str(testXImg.shape))\nprint (\"test_set_y shape: \" + str(testY.shape))","metadata":{"execution":{"iopub.status.busy":"2021-12-28T06:49:47.792181Z","iopub.execute_input":"2021-12-28T06:49:47.792447Z","iopub.status.idle":"2021-12-28T06:49:47.802404Z","shell.execute_reply.started":"2021-12-28T06:49:47.792413Z","shell.execute_reply":"2021-12-28T06:49:47.801189Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print (\"trainXFlat shape: \" + str(trainXFlat.shape))\nprint (\"trainY shape: \" + str(trainY.shape))\nprint (\"testXFlat shape: \" + str(testXFlat.shape))\nprint (\"testY shape: \" + str(testY.shape))","metadata":{"execution":{"iopub.status.busy":"2021-12-28T06:49:47.804203Z","iopub.execute_input":"2021-12-28T06:49:47.804502Z","iopub.status.idle":"2021-12-28T06:49:47.821578Z","shell.execute_reply.started":"2021-12-28T06:49:47.804447Z","shell.execute_reply":"2021-12-28T06:49:47.820249Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"<a name='2-3'></a>\n### Test the function by getting some of the images and outputting their status","metadata":{}},{"cell_type":"code","source":"trainPlot = plt.imshow(trainXImg[32])\nprint(\"Either 0 (normal) or 1 (pneumonia): \" + str(trainY[0][32]))","metadata":{"execution":{"iopub.status.busy":"2021-12-28T06:49:47.823020Z","iopub.execute_input":"2021-12-28T06:49:47.823356Z","iopub.status.idle":"2021-12-28T06:49:48.186206Z","shell.execute_reply.started":"2021-12-28T06:49:47.823307Z","shell.execute_reply":"2021-12-28T06:49:48.185161Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"testPlot = plt.imshow(testXImg[64])\nprint(\"Either 0 (normal) or 1 (pneumonia): \" + str(testY[0][64]))","metadata":{"execution":{"iopub.status.busy":"2021-12-28T06:49:48.188028Z","iopub.execute_input":"2021-12-28T06:49:48.188379Z","iopub.status.idle":"2021-12-28T06:49:48.654493Z","shell.execute_reply.started":"2021-12-28T06:49:48.188333Z","shell.execute_reply":"2021-12-28T06:49:48.653413Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"<a name='3'></a>\n## Section 3 - Create helper functions\n1. initialize the parameters\n2. model forward\n3. Sigmoid activation function\n3. ReLU activation function","metadata":{}},{"cell_type":"markdown","source":"### Intialize the parameters","metadata":{}},{"cell_type":"code","source":"def initParams(layerDims):\n    params = {}\n    L = len(layerDims)            # number of layers in the network\n\n    for l in range(1, L):\n        params['W' + str(l)] = np.random.randn(layerDims[l], layerDims[l-1]) * 0.01\n        params['b' + str(l)] = np.zeros((layerDims[l], 1))\n        \n        assert(params['W' + str(l)].shape == (layerDims[l], layerDims[l-1]))\n        assert(params['b' + str(l)].shape == (layerDims[l], 1))\n        \n    return params","metadata":{"execution":{"iopub.status.busy":"2021-12-28T06:49:48.656197Z","iopub.execute_input":"2021-12-28T06:49:48.656640Z","iopub.status.idle":"2021-12-28T06:49:48.666350Z","shell.execute_reply.started":"2021-12-28T06:49:48.656591Z","shell.execute_reply":"2021-12-28T06:49:48.665042Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Model Forward","metadata":{}},{"cell_type":"code","source":"def modelForward(X, params):\n    caches = []\n    A = X\n    L = len(params) // 2                  # number of layers in the neural network\n    \n    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n    for l in range(1, L):\n        A_prev = A \n        A, cache = linearActivationForward(A_prev, params['W' + str(l)], params['b' + str(l)], activation = \"relu\")\n        caches.append(cache)\n    \n    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n    AL, cache = linearActivationForward(A, params['W' + str(L)], params['b' + str(L)], activation = \"sigmoid\")\n    caches.append(cache)\n    \n    assert(AL.shape == (1,X.shape[1]))\n            \n    return AL, caches\n\n# sub-helper functions for modelForward\n# performs the linear step\ndef linearForward(A, W, b):\n    Z = W.dot(A) + b\n    \n    assert(Z.shape == (W.shape[0], A.shape[1]))\n    cache = (A, W, b)\n    \n    return Z, cache\n\n# performs the activation step\ndef linearActivationForward(A_prev, W, b, activation):\n    if activation == \"sigmoid\":\n        Z, linearCache = linearForward(A_prev, W, b)\n        A, activationCache = sigmoid(Z)\n    \n    elif activation == \"relu\":\n        Z, linearCache = linearForward(A_prev, W, b)\n        A, activationCache = relu(Z)\n    \n    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n    cache = (linearCache, activationCache)\n\n    return A, cache\n\n# computing the simple relu and sigmoid functions\ndef sigmoid(Z):\n    A = 1/(1+np.exp(-Z))\n    cache = Z\n    \n    return A, cache\ndef relu(Z):\n    A = np.maximum(0,Z)\n    \n    assert(A.shape == Z.shape)\n    \n    cache = Z \n    return A, cache","metadata":{"execution":{"iopub.status.busy":"2021-12-28T06:49:48.668138Z","iopub.execute_input":"2021-12-28T06:49:48.668523Z","iopub.status.idle":"2021-12-28T06:49:48.689229Z","shell.execute_reply.started":"2021-12-28T06:49:48.668451Z","shell.execute_reply":"2021-12-28T06:49:48.688063Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Compute Cost","metadata":{}},{"cell_type":"code","source":"def computeCost(AL, Y):\n    m = Y.shape[1]\n\n    # Compute loss from aL and y.\n    cost = (1./m) * (-np.dot(Y,np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T))\n    \n    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n    assert(cost.shape == ())\n    \n    return cost ","metadata":{"execution":{"iopub.status.busy":"2021-12-28T06:49:48.691284Z","iopub.execute_input":"2021-12-28T06:49:48.691877Z","iopub.status.idle":"2021-12-28T06:49:48.710180Z","shell.execute_reply.started":"2021-12-28T06:49:48.691822Z","shell.execute_reply":"2021-12-28T06:49:48.709335Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Model Backward","metadata":{}},{"cell_type":"code","source":"def modelBackward(AL, Y, caches):\n    grads = {}\n    L = len(caches) # the number of layers\n    m = AL.shape[1]\n    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n    \n    # Initializing the backpropagation\n    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n    \n    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"AL, Y, caches\". Outputs: \"grads[\"dAL\"], grads[\"dWL\"], grads[\"dbL\"]\n    currentCache = caches[L-1]\n    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linearActivationBackward(dAL, currentCache, activation = \"sigmoid\")\n    \n    for l in reversed(range(L-1)):\n        # lth layer: (RELU -> LINEAR) gradients.\n        currentCache = caches[l]\n        dA, dW, db = linearActivationBackward(grads[\"dA\" + str(l + 1)], currentCache, activation = \"relu\")\n        grads[\"dA\" + str(l)] = dA\n        grads[\"dW\" + str(l + 1)] = dW\n        grads[\"db\" + str(l + 1)] = db\n\n    return grads\n\n# sub-helper functions\n# calculates the linear backward step\ndef linearBackward(dZ, cache):\n    A_prev, W, b = cache\n    m = A_prev.shape[1]\n\n    dW = 1./m * np.dot(dZ,A_prev.T)\n    db = 1./m * np.sum(dZ, axis = 1, keepdims = True)\n    dA_prev = np.dot(W.T,dZ)\n    \n    assert (dA_prev.shape == A_prev.shape)\n    assert (dW.shape == W.shape)\n    assert (db.shape == b.shape)\n    \n    return dA_prev, dW, db\n\n# computes the backwards activation step\ndef linearActivationBackward(dA, cache, activation):\n    linearCache, activationCache = cache\n    \n    if activation == \"relu\":\n        dZ = reluBackward(dA, activationCache)\n        dA_prev, dW, db = linearBackward(dZ, linearCache)\n        \n    elif activation == \"sigmoid\":\n        dZ = sigmoidBackward(dA, activationCache)\n        dA_prev, dW, db = linearBackward(dZ, linearCache)\n    \n    return dA_prev, dW, db\n\n# computes the backwards relu and sigmoid derivatives\ndef reluBackward(dA, cache):\n    Z = cache\n    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n    \n    # When z <= 0, you should set dz to 0 as well. \n    dZ[Z <= 0] = 0\n    \n    assert (dZ.shape == Z.shape)\n    \n    return dZ\ndef sigmoidBackward(dA, cache):\n    Z = cache\n    \n    s = 1/(1+np.exp(-Z))\n    dZ = dA * s * (1-s)\n    \n    assert (dZ.shape == Z.shape)\n    \n    return dZ ","metadata":{"execution":{"iopub.status.busy":"2021-12-28T06:49:48.711429Z","iopub.execute_input":"2021-12-28T06:49:48.712310Z","iopub.status.idle":"2021-12-28T06:49:48.733527Z","shell.execute_reply.started":"2021-12-28T06:49:48.712264Z","shell.execute_reply":"2021-12-28T06:49:48.732380Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Update parameters","metadata":{}},{"cell_type":"code","source":"def updateParams(params, grads, LR):\n    L = len(params) // 2 # number of layers in the neural network\n\n    # Update rule for each parameter. Use a for loop.\n    for l in range(L):\n        params[\"W\" + str(l+1)] = params[\"W\" + str(l+1)] - LR * grads[\"dW\" + str(l+1)]\n        params[\"b\" + str(l+1)] = params[\"b\" + str(l+1)] - LR * grads[\"db\" + str(l+1)]\n        \n    return params","metadata":{"execution":{"iopub.status.busy":"2021-12-28T06:49:48.734731Z","iopub.execute_input":"2021-12-28T06:49:48.735518Z","iopub.status.idle":"2021-12-28T06:49:48.753922Z","shell.execute_reply.started":"2021-12-28T06:49:48.735437Z","shell.execute_reply":"2021-12-28T06:49:48.752726Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Section 4 - One function to rule them all\nThis function implements all of the previous helper functions to create the neural network by implementing gradient descent\n- It performs forward propogation\n- computes the cost function (how different y and yhat are)\n- performs back propogation\n- and updates the parameters to make the parameters closer to correct","metadata":{}},{"cell_type":"code","source":"def simpleNN(X, Y, layerDims, LR, numIters):\n    \n    # create vars to store some values\n    np.random.seed(7)\n    costs = []\n    params = initParams(layerDims)\n    \n    # iterate through the number of iterations\n    for i in range(0, numIters):\n        \n        # model forward\n        Yhat, caches = modelForward(X, params)\n        # compute the cost\n        cost = computeCost(Yhat, Y)\n        # model backward\n        grads = modelBackward(Yhat, Y, caches)\n        # update paramters\n        params = updateParams(params, grads, LR)\n        \n        # print the cost\n        print(\"cost after {} iterations: {}\".format(i+1, np.squeeze(cost)))\n        costs.append(cost)\n            \n    return params, costs","metadata":{"execution":{"iopub.status.busy":"2021-12-28T06:49:48.756943Z","iopub.execute_input":"2021-12-28T06:49:48.757348Z","iopub.status.idle":"2021-12-28T06:49:48.771660Z","shell.execute_reply.started":"2021-12-28T06:49:48.757316Z","shell.execute_reply":"2021-12-28T06:49:48.770569Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Section 5 - Calculating predictions\nCreate a function to calculate the predictions","metadata":{}},{"cell_type":"code","source":"def predict(X, Y, params):\n    \n    m = X.shape[1]\n    n = len(params) // 2 # number of layers in the neural network\n    p = np.zeros((1,m))\n    \n    # Forward propagation\n    probs, caches = modelForward(X, params)\n\n    # convert probs to 0/1 predictions\n    for i in range(0, probs.shape[1]):\n        if probs[0,i] > 0.5:\n            p[0,i] = 1\n        else:\n            p[0,i] = 0\n    \n    print(\"Accuracy: \" + str(np.sum((p == Y)/m)))\n        \n    return p","metadata":{"execution":{"iopub.status.busy":"2021-12-28T06:49:48.773431Z","iopub.execute_input":"2021-12-28T06:49:48.773984Z","iopub.status.idle":"2021-12-28T06:49:48.786407Z","shell.execute_reply.started":"2021-12-28T06:49:48.773932Z","shell.execute_reply":"2021-12-28T06:49:48.784984Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Section 6 - Training the model\n- finalize the parameters and costs","metadata":{}},{"cell_type":"code","source":"# initialize the constants\nlayerDims = [trainXVec, 20, 7, 5, 1]\nlearningRate = 0.01\nnumIterations = 30\n\n# call the training function\nparams, costs = simpleNN(trainX, trainY, layerDims, learningRate, numIterations)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T06:49:48.787937Z","iopub.execute_input":"2021-12-28T06:49:48.788220Z","iopub.status.idle":"2021-12-28T06:54:35.334389Z","shell.execute_reply.started":"2021-12-28T06:49:48.788187Z","shell.execute_reply":"2021-12-28T06:54:35.333588Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# graph the cost\niters = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]\nplt.plot(iters,costs)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-28T06:54:35.336286Z","iopub.execute_input":"2021-12-28T06:54:35.336845Z","iopub.status.idle":"2021-12-28T06:54:35.552684Z","shell.execute_reply.started":"2021-12-28T06:54:35.336805Z","shell.execute_reply":"2021-12-28T06:54:35.551562Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Section 7 - Testing the model\n- First on the training data ~ hopefully around 0.99 Accuracy\n- Then on the testing data","metadata":{}},{"cell_type":"markdown","source":"First, a sanity check by predicting the training data. The model should have already seen these images, so it should easily be able to predict these","metadata":{}},{"cell_type":"code","source":"trainPred = predict(trainX, trainY, params)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T06:54:35.554209Z","iopub.execute_input":"2021-12-28T06:54:35.554524Z","iopub.status.idle":"2021-12-28T06:54:39.063170Z","shell.execute_reply.started":"2021-12-28T06:54:35.554453Z","shell.execute_reply":"2021-12-28T06:54:39.061943Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Next, trying to predict the testing images","metadata":{}},{"cell_type":"code","source":"testPred = predict(testX, testY, params)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T06:54:39.065021Z","iopub.execute_input":"2021-12-28T06:54:39.071588Z","iopub.status.idle":"2021-12-28T06:54:39.648078Z","shell.execute_reply.started":"2021-12-28T06:54:39.071494Z","shell.execute_reply":"2021-12-28T06:54:39.646974Z"},"trusted":true},"execution_count":19,"outputs":[]}]}